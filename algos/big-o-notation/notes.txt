There are 10 - 20 solutions for a lot of problems, how do you determine which one is best?

Big O is a system or generalization on how to compare and talk about code? for example "write a function that accepts a string input and returns a reversed copy"

Computers have the same issue, and Big O notation is a way to measure the complexity of a solution, essentially how easy or hard it is. It does this by relating the amount of data you are working with to how many steps (roughly equivalent to how much time) it will take for a particular solution, or algorithm, will take.

O(1) means the algorithm takes the same amount of time to run regardless of the size of the input. This is a bit of a holy grail, and not often attained. In some data structures, retrieving a single element is O(1).

O(log n) means the algorithm's speed drops very little as the input grows. It might mean you need to increase the input size by ten times before the algorithm's speed drops.

O(n) means the algorithm's speed is linear with the input size. Adding up a set of numbers requires you to look at each of the numbers, so adding ten thousand numbers takes ten times as long as adding a thousand numbers.

O stands for Order, in like the order of growth

Big O gives us a number telling us how efficient it is. 

You should care because of performance. In a large data set can make the difference in hours on running a solution. Big O gives us precise vocabulary which helps make it useful for discussing trade-offs between approaches.

'When we're talking about algorithms (recipes for solving problems), we care about how fast an algorithm is. Specifically, what we often care about is how fast an algorithm can be given a big set of inputs. If you need to sort five children in order of age, the algorithm speed barely matters; but if you need to sort ten million children in order of age, then choosing the wrong algorithm can mean the difference between a runtime of a few minutes and a few days.'

It also helps you see where your code is slowing down or crashing.

-- THE PROBLEM WITH TIME --
1. different machines will record different times
2. The same machine will record different times.
3. Fast algorithms, speed measurements may not be precise enough

Rather than count time we can count the number of operations the computer has to do.

an algorithm is O(f(n)) (BIG O of f of n) if the number of simple operations the computer has to do is eventually less than a constant times f(n), and n increases.

- linear (f(n) = n) as n scales so does the runtime at a similar rate = O(n)

- quadratic (f(n) = n2) as n grows the runtime is square of n = O(n(squared))

- constant (f(n) = 1) runetime does not scale as n grows = O(1)

- can also be entirely different

----------------------------------------------------
Simplyfying Big O Expressions

Constants don't matter, simplify as much as possible
- O(2n) vs O(n) and O(500) O(1) is the same as they do the same number of things each run time
- O(13n(squared)) = O(n(squared))

Smaller Terms Dont Matter 
take O(n(squared) + 5n + 8) for instance, if n is 1,000 the 5n barely matters so it would be O(n(squared))

big O Shorthands
- Arithmetic Operations are Constant
- Variable assignment is constant
- Accessing elements in a array by index or key is constant
- In a loop, the complexity is the length of the loop


----------------------------------------------------

space complexity

- most primitives are constant space
- strings require O(n), same as reference types (arrays objects)

Time is usually more important than space as space (disk space) is 'cheap'
----------------------------------------------------

logarithms

Its a exponent
Kinda like how 3+?=7 you can do with 7-3=?

Log_a(b)=c <==> a(c) = b
Alogarithm is just finding the exponent of a number

log_superscript_2(8) = 3, reads as log base 2 of 8 is equal to 3
2, to what power, equals 8
